#!/bin/bash

# AICrawler Run Script

echo "ğŸ•·ï¸ AICrawler - Web Ä°Ã§erik Toplama ve Temizleme Sistemi"
echo "=================================================="
echo ""

# Check if virtual environment exists
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Sanal ortam bulunamadÄ±. OluÅŸturuluyor..."
    python3 -m venv venv
fi

# Activate virtual environment
echo "ğŸ”§ Sanal ortam aktifleÅŸtiriliyor..."
source venv/bin/activate 2>/dev/null || venv\Scripts\activate

# Install requirements if needed
echo "ğŸ“š BaÄŸÄ±mlÄ±lÄ±klar kontrol ediliyor..."
pip install -q -r requirements.txt

# Create necessary directories
mkdir -p data/exports

echo ""
echo "âœ… Kurulum tamamlandÄ±!"
echo ""
echo "SeÃ§enekler:"
echo "1) Streamlit Web ArayÃ¼zÃ¼nÃ¼ BaÅŸlat"
echo "2) Test Script'ini Ã‡alÄ±ÅŸtÄ±r"
echo "3) Python Shell'i AÃ§"
echo "4) Ã‡Ä±kÄ±ÅŸ"
echo ""

read -p "SeÃ§iminiz (1-4): " choice

case $choice in
    1)
        echo ""
        echo "ğŸš€ Streamlit arayÃ¼zÃ¼ baÅŸlatÄ±lÄ±yor..."
        echo "TarayÄ±cÄ±nÄ±zda http://localhost:8501 adresine gidin"
        echo ""
        streamlit run app.py
        ;;
    2)
        echo ""
        echo "ğŸ§ª Test script'i Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor..."
        echo ""
        python test_crawler.py
        ;;
    3)
        echo ""
        echo "ğŸ Python shell aÃ§Ä±lÄ±yor..."
        echo "Ã–rnek kullanÄ±m:"
        echo ">>> from src.core.workflow import CrawlerPipeline"
        echo ">>> pipeline = CrawlerPipeline()"
        echo ">>> result = pipeline.crawl('https://example.com', max_depth=2, max_pages=10)"
        echo ""
        python
        ;;
    4)
        echo "ğŸ‘‹ GÃ¼le gÃ¼le!"
        exit 0
        ;;
    *)
        echo "âŒ GeÃ§ersiz seÃ§im!"
        exit 1
        ;;
esac